import java.time.Duration;
import java.time.Instant;
import java.util.Properties;
import java.util.Random;
import java.util.UUID;
import java.util.Collections;
import java.net.InetAddress;
import java.net.UnknownHostException;

import java.util.concurrent.ExecutionException;

import com.google.common.collect.ImmutableMap;

import com.google.gson.JsonElement;
import com.google.gson.JsonObject;
import com.google.gson.JsonParser;
import io.lettuce.core.RedisClient;
import io.lettuce.core.api.StatefulRedisConnection;
import io.lettuce.core.api.sync.RedisCommands;
import io.opentracing.SpanContext;
import io.opentracing.contrib.kafka.TracingKafkaUtils;
import io.opentracing.contrib.redis.lettuce.TracingStatefulRedisConnection;
import jdk.nashorn.internal.parser.JSONParser;
import org.apache.kafka.clients.producer.RecordMetadata;
import org.apache.kafka.common.serialization.IntegerSerializer;
import org.apache.kafka.common.serialization.StringSerializer;
import org.apache.kafka.clients.consumer.Consumer;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.PartitionInfo;
import org.apache.kafka.common.serialization.IntegerDeserializer;
import org.apache.kafka.common.serialization.IntegerSerializer;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.common.serialization.StringSerializer;

import io.jaegertracing.Configuration;
import io.jaegertracing.Configuration.ReporterConfiguration;
import io.jaegertracing.Configuration.SamplerConfiguration;
import io.jaegertracing.Configuration.SenderConfiguration;
import io.jaegertracing.internal.JaegerTracer;
import io.opentracing.Scope;
import io.opentracing.Tracer;
import io.opentracing.contrib.kafka.TracingKafkaConsumer;
import io.opentracing.util.GlobalTracer;

/*
 * This Java source file was generated by the Gradle 'init' task.
 */
public class App {
    private final static String JAEGER_AGENT_HOST = "localhost";

    private static Consumer<Integer, String> createConsumer() throws UnknownHostException {
        final Properties props = new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put("client.id", InetAddress.getLocalHost().getHostName());
        props.put(ConsumerConfig.GROUP_ID_CONFIG, "storage-service");
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class.getName());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 1000);
        props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, "100");
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);
        props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, "15000");

        final Consumer<Integer, String> consumer = new TracingKafkaConsumer<>(new KafkaConsumer<>(props), GlobalTracer.get());
        return consumer;
    }

    public static void initTracer(String service) {
        Tracer tracer = new Configuration(service)
            .withSampler(
                new SamplerConfiguration()
                .withType("const")
                .withParam(1)
            )
            .withReporter(
                new ReporterConfiguration()
                .withSender(
                    new SenderConfiguration()
                    .withAgentHost(JAEGER_AGENT_HOST)
                )
            )
            .getTracer();
        GlobalTracer.register(tracer);
    }

    public static void main(String[] args) throws UnknownHostException, InterruptedException {
        initTracer("storage-service");

        // redis client
        RedisClient client = RedisClient.create("redis://localhost");
        StatefulRedisConnection<String, String> connection = new TracingStatefulRedisConnection<>(client.connect(), GlobalTracer.get(), false);
        RedisCommands<String, String> syncCommands = connection.sync();

        // kafka consumer
        Consumer<Integer, String> consumer = createConsumer();
        String topic = "message";
        consumer.subscribe(Collections.singletonList(topic));
        ConsumerRecords<Integer, String> consumerRecords;

        while (true) {
            System.out.println("POLLING");
            consumerRecords = consumer.poll(1000);
            System.out.println("DONE POLLING");

            consumerRecords.forEach(record -> {
                SpanContext spanContext = TracingKafkaUtils.extractSpanContext(record.headers(), GlobalTracer.get());
                try (Scope scope = GlobalTracer.get().buildSpan("store").asChildOf(spanContext).startActive(true)) {
                    System.out.printf("Consumer Record:(%d, %s, %d, %d)\n", record.key(), record.value(), record.partition(), record.offset());
                    // parse json
                    String jsonString = record.value();
                    JsonParser jsonParser = new JsonParser();
                    JsonObject json = (JsonObject)jsonParser.parse(jsonString);
                    String id = json.get("id").getAsString();
                    String room = json.get("room").getAsString();
                    String date = json.get("date").getAsString();
                    Long epoch = Instant.parse(date).getEpochSecond();
                    // intentionally introduce delay here...
                    // try {
                    //     Thread.sleep(5000);
                    // } catch (Exception e) {
                    //     e.printStackTrace();
                    // }
                    syncCommands.set("message:" + id, jsonString);
                    syncCommands.zadd(room, epoch.doubleValue(), id);
                }
            });

            consumer.commitAsync();
            System.out.println("DONE");
            Thread.sleep(1000);
        }
    }
}
